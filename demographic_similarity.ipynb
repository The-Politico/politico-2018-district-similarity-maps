{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![POLITICO](https://rawgithub.com/The-Politico/src/master/images/logo/badge.png)\n",
    "\n",
    "# POLITICO demographic district similarity maps\n",
    "\n",
    "POLITICO partisan voting district similarity maps align districts by their similarity based on demographic stats from the U.S. Census.\n",
    "\n",
    "The maps are created by calculating a weighted [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance) between districts based on their demographic characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The data\n",
    "\n",
    "The demographic profile for each district is based on these characteristics:\n",
    "\n",
    "- Non-hispanic white percent of population (ACS table B03002)\n",
    "- Non-hispanic black percent of population (B03002)\n",
    "- Non-hispanic asian percent of population (B03002)\n",
    "- Hispanic percent of population (B03002)\n",
    "- Median Age (B01002)\n",
    "- Median Income (B19013)\n",
    "- Education attainment (some college or greater) (B15003)\n",
    "- Population density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Calculate weights\n",
    "\n",
    "We weight demographic variables by how significant they are in shaping a district's political identity. To do that, we statistically measure the relationship between the variables and voting behavior using a linear model.\n",
    "\n",
    "While our goal is to determine the similarity of districts, we actually use county-level data to calculate our weights. Because there are more counties than districts, counties give us a more robust picture of the relationship between demographics and voting.\n",
    "\n",
    "Our voting data is 2012 and 2016 presidential results. Our demographic data comes from the 2012 and 2016 5-year American Community Survey from the U.S. Census. (In the linear model, we weight recent data more heavily.)\n",
    "\n",
    "To calculate the weights for demographics, we need to estimate how influential each variable is compared to each other in terms of its impact on party margin.\n",
    "\n",
    "To begin we normalize our demographic variables to a scale of 0 to 1 representing the min and max of each variable's distribution. That way we can compare their model coefficients. We then take the absolute value of the coefficients. That ratio represents how influential they are compared to each other when used together to predict voting behavior. These are our weights.\n",
    "\n",
    "For example, if non-hispanic whiteness has a coefficient of -4 while income has a coefficent of 1 in the model, we weight whiteness 4 to 1 when calculating the Euclidean distance between districts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get county census data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from census import Census\n",
    "from us import states\n",
    "\n",
    "c = Census(os.getenv('CENSUS_API_KEY'))\n",
    "\n",
    "\n",
    "def get_census_series(year):\n",
    "    FIPS = {}\n",
    "    \n",
    "    def add_to_fips(d):\n",
    "        if d[\"fips\"] not in FIPS:\n",
    "            FIPS[d[\"fips\"]] = {}\n",
    "        FIPS[d[\"fips\"]] = {**FIPS[d[\"fips\"]], **d}\n",
    "    \n",
    "    def normalize_values(label, collection):\n",
    "        values = [d[label] for d in collection]\n",
    "        max_value = max(values)\n",
    "        min_value = min(values)\n",
    "        for d in collection:\n",
    "            d[label + \"_norm\"] = (d[label] - min_value) / (max_value - min_value)\n",
    "            add_to_fips(d)\n",
    "        \n",
    "    \n",
    "    # WHITE\n",
    "    \n",
    "    white = [{\n",
    "        \"fips\": w[\"state\"] + w[\"county\"],\n",
    "        \"year\": str(year),\n",
    "        \"white\": w[\"B03002_003E\"] / w[\"B03002_001E\"]\n",
    "    } for w in c.acs5.get(['B03002_003E', 'B03002_001E'], {'for': 'county:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"white\", white)\n",
    "    \n",
    "    # Black\n",
    "    \n",
    "    black = [{\n",
    "        \"fips\": b[\"state\"] + b[\"county\"],\n",
    "        \"year\": str(year),\n",
    "        \"black\": b[\"B03002_004E\"] / b[\"B03002_001E\"]\n",
    "    } for b in c.acs5.get(['B03002_004E', 'B03002_001E'], {'for': 'county:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"black\", black)\n",
    "    \n",
    "    \n",
    "    # Hispanic\n",
    "    \n",
    "    hispanic = [{\n",
    "        \"fips\": h[\"state\"] + h[\"county\"],\n",
    "        \"year\": str(year),\n",
    "        \"hispanic\": h[\"B03002_012E\"] / h[\"B03002_001E\"]\n",
    "    } for h in c.acs5.get(['B03002_012E', 'B03002_001E'], {'for': 'county:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"hispanic\", hispanic)\n",
    "    \n",
    "    \n",
    "    # Asian\n",
    "    \n",
    "    asian = [{\n",
    "        \"fips\": h[\"state\"] + h[\"county\"],\n",
    "        \"year\": str(year),\n",
    "        \"asian\": h[\"B03002_006E\"] / h[\"B03002_001E\"]\n",
    "    } for h in c.acs5.get(['B03002_006E', 'B03002_001E'], {'for': 'county:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"asian\", asian)\n",
    "    \n",
    "\n",
    "    \n",
    "    # AGE\n",
    "    \n",
    "    age = [{\n",
    "        \"fips\": a[\"state\"] + a[\"county\"],\n",
    "        \"year\": str(year),\n",
    "        \"age\": a[\"B01002_001E\"]\n",
    "    } for a in c.acs5.get('B01002_001E', {'for': 'county:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"age\", age)\n",
    "\n",
    "    \n",
    "    # INCOME\n",
    "    \n",
    "    income = [{\n",
    "        \"fips\": i[\"state\"] + i[\"county\"],\n",
    "        \"year\": str(year),\n",
    "        \"income\": i[\"B19013_001E\"]\n",
    "    } for i in c.acs5.get('B19013_001E', {'for': 'county:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"income\", income)\n",
    "    \n",
    "    \n",
    "    # EDUCATION\n",
    "\n",
    "    education = [{\n",
    "        \"fips\": e[\"state\"] + e[\"county\"],\n",
    "        \"year\": str(year),\n",
    "        \"education\": (\n",
    "            e[\"B15003_019E\"] +\n",
    "            e[\"B15003_020E\"] +\n",
    "            e[\"B15003_021E\"] +\n",
    "            e[\"B15003_022E\"] +\n",
    "            e[\"B15003_023E\"] +\n",
    "            e[\"B15003_024E\"] +\n",
    "            e[\"B15003_025E\"]\n",
    "        ) / e[\"B15003_001E\"],\n",
    "    } for e in c.acs5.get([\n",
    "        'B15003_001E',\n",
    "        'B15003_019E',\n",
    "        'B15003_020E',\n",
    "        'B15003_021E',\n",
    "        'B15003_022E',\n",
    "        'B15003_023E',\n",
    "        'B15003_024E',\n",
    "        'B15003_025E'\n",
    "    ], {'for': 'county:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"education\", education)\n",
    "    \n",
    "    \n",
    "    # DENSITY\n",
    "\n",
    "    POP = {}\n",
    "    for d in c.acs5.get(['B01003_001E'], {'for': 'county:*'}, year=year):\n",
    "        fips = d[\"state\"] + d[\"county\"]\n",
    "        POP[fips] = int(d[\"B01003_001E\"])\n",
    "    \n",
    "    density = [\n",
    "        {\n",
    "            \"fips\": d[\"state\"] + d[\"county\"],\n",
    "            \"density\": POP[d[\"state\"] + d[\"county\"]] / int(d[\"AREALAND\"])\n",
    "        } for d in c.sf1.get('AREALAND', {'for': 'county:*'}, year=2010) if d[\"state\"] + d[\"county\"] in POP\n",
    "    ]\n",
    "    \n",
    "    normalize_values(\"density\", density)\n",
    "    \n",
    "    return FIPS\n",
    "\n",
    "\n",
    "CENSUS_2016 = get_census_series(2016)\n",
    "CENSUS_2012 = get_census_series(2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get county election data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_results_series(year):\n",
    "    response = requests.get('https://raw.githubusercontent.com/The-Politico/presidential-county-data/master/output/{}.csv'.format(year))\n",
    "\n",
    "    results = {}\n",
    "    reader = csv.DictReader(io.StringIO(response.text))\n",
    "    for row in reader:\n",
    "        fips = row['county_fips']\n",
    "        results[fips] = {\n",
    "            \"dem\": int(row['democrat']),\n",
    "            \"dem_pct\": int(row[\"democrat\"]) / int(row[\"total\"]),\n",
    "            \"gop\": int(row['republican']),\n",
    "            \"gop_pct\": int(row[\"republican\"]) / int(row[\"total\"]),\n",
    "            \"total\": int(row['total']),\n",
    "            \"margin\": (int(row[\"democrat\"]) / int(row[\"total\"])) - (int(row[\"republican\"]) / int(row[\"total\"]))\n",
    "        }\n",
    "    return results\n",
    "\n",
    "RESULTS_2012 = get_results_series(2012)\n",
    "RESULTS_2016 = get_results_series(2016)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmcclure/Scripts/politico-2018-district-similarity-maps/.venv/lib/python3.6/site-packages/sklearn/linear_model/base.py:485: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython.display import display\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "w = []\n",
    "\n",
    "\n",
    "def add_to_model(DEMOGRAPHICS, VOTING, WEIGHT):\n",
    "    for fips, demos in DEMOGRAPHICS.items():\n",
    "        if fips not in VOTING:\n",
    "            continue\n",
    "        y.append(VOTING[fips][\"margin\"])\n",
    "        X.append([\n",
    "            demos[\"white_norm\"],\n",
    "            demos[\"black_norm\"],\n",
    "            demos[\"hispanic_norm\"],\n",
    "            demos[\"asian_norm\"],\n",
    "            demos[\"age_norm\"],\n",
    "            demos[\"income_norm\"],\n",
    "            demos[\"education_norm\"],\n",
    "            demos[\"density_norm\"],\n",
    "        ])\n",
    "        w.append(WEIGHT)\n",
    "\n",
    "add_to_model(CENSUS_2016, RESULTS_2016, 2)\n",
    "add_to_model(CENSUS_2012, RESULTS_2012, 1)\n",
    "\n",
    "model = LinearRegression().fit(X, y, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R<sup>2</sup>\n",
    "\n",
    "Currently the model predicts ~45% of the variation in party margin for each county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4548465203054187"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model.score(X, y, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients\n",
    "\n",
    "These coefficients are for our normalized values, which all fit in the range 0 - 1. We interpret them to indicate the relative strength of any one variable relative to the others in determining the two party vote margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'white': -0.6925013874350867,\n",
       " 'black': 0.356000358828075,\n",
       " 'hispanic': -0.24205959230946833,\n",
       " 'asian': 0.9221360218062666,\n",
       " 'age': 0.11822108301928899,\n",
       " 'income': -0.18014078676637332,\n",
       " 'education': 0.645780266460257,\n",
       " 'density': 1.0368261642579768}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefficients = {\n",
    "    'white': model.coef_[0],\n",
    "    'black': model.coef_[1],\n",
    "    'hispanic': model.coef_[2],\n",
    "    'asian': model.coef_[3],\n",
    "    'age': model.coef_[4],\n",
    "    'income': model.coef_[5],\n",
    "    'education': model.coef_[6],\n",
    "    'density': model.coef_[7]\n",
    "}\n",
    "display(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights\n",
    "\n",
    "We use the absolute value of the coefficients as our weights because we don't care about the _direction_ of the effect just the _size_ of it relative to the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = {\n",
    "    \"white\": abs(coefficients[\"white\"]),\n",
    "    \"black\": abs(coefficients[\"black\"]),\n",
    "    \"hispanic\": abs(coefficients[\"hispanic\"]),\n",
    "    \"asian\": abs(coefficients[\"asian\"]),\n",
    "    \"age\": abs(coefficients[\"age\"]),\n",
    "    \"income\": abs(coefficients[\"income\"]),\n",
    "    \"education\": abs(coefficients[\"education\"]),\n",
    "    \"density\": abs(coefficients[\"density\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Calculate district similarity\n",
    "\n",
    "### Get district census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import us\n",
    "\n",
    "def get_district_census_series(year):\n",
    "    DISTRICTS = {}\n",
    "    \n",
    "    def add_to_fips(d):\n",
    "        if d[\"district\"] not in DISTRICTS:\n",
    "            DISTRICTS[d[\"district\"]] = {}\n",
    "        DISTRICTS[d[\"district\"]] = {**DISTRICTS[d[\"district\"]], **d}\n",
    "    \n",
    "    def normalize_values(label, collection):\n",
    "        values = [d[label] for d in collection]\n",
    "        max_value = max(values)\n",
    "        min_value = min(values)\n",
    "        for d in collection:\n",
    "            d[label + \"_norm\"] = (d[label] - min_value) / (max_value - min_value)\n",
    "            add_to_fips(d)\n",
    "    \n",
    "    def district_id(d):\n",
    "        state_postal = us.states.lookup(d[\"state\"]).abbr\n",
    "        district = d[\"congressional district\"]\n",
    "        return \"{}-{}\".format(state_postal, district)\n",
    "        \n",
    "    \n",
    "    # WHITE\n",
    "    \n",
    "    white = [{\n",
    "        \"district\": district_id(w),\n",
    "        \"year\": str(year),\n",
    "        \"white\": w[\"B03002_003E\"] / w[\"B03002_001E\"]\n",
    "    } for w in c.acs5.get(['B03002_003E', 'B03002_001E'], {'for': 'congressional district:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"white\", white)\n",
    "    \n",
    "    \n",
    "    # Black\n",
    "    \n",
    "    black = [{\n",
    "        \"district\": district_id(b),\n",
    "        \"year\": str(year),\n",
    "        \"black\": b[\"B03002_004E\"] / b[\"B03002_001E\"]\n",
    "    } for b in c.acs5.get(['B03002_004E', 'B03002_001E'], {'for': 'congressional district:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"black\", black)\n",
    "    \n",
    "    \n",
    "    # Hispanic\n",
    "    \n",
    "    hispanic = [{\n",
    "        \"district\": district_id(h),\n",
    "        \"year\": str(year),\n",
    "        \"hispanic\": h[\"B03002_012E\"] / h[\"B03002_001E\"]\n",
    "    } for h in c.acs5.get(['B03002_012E', 'B03002_001E'], {'for': 'congressional district:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"hispanic\", hispanic)\n",
    "    \n",
    "    \n",
    "    # Asian\n",
    "    \n",
    "    asian = [{\n",
    "        \"district\": district_id(h),\n",
    "        \"year\": str(year),\n",
    "        \"asian\": h[\"B03002_006E\"] / h[\"B03002_001E\"]\n",
    "    } for h in c.acs5.get(['B03002_006E', 'B03002_001E'], {'for': 'congressional district:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"asian\", asian)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # AGE\n",
    "    \n",
    "    age = [{\n",
    "        \"district\": district_id(a),\n",
    "        \"year\": str(year),\n",
    "        \"age\": a[\"B01002_001E\"]\n",
    "    } for a in c.acs5.get('B01002_001E', {'for': 'congressional district:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"age\", age)\n",
    "\n",
    "    \n",
    "    # INCOME\n",
    "    \n",
    "    income = [{\n",
    "        \"district\": district_id(i),\n",
    "        \"year\": str(year),\n",
    "        \"income\": i[\"B19013_001E\"]\n",
    "    } for i in c.acs5.get('B19013_001E', {'for': 'congressional district:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"income\", income)\n",
    "    \n",
    "    \n",
    "    # EDUCATION\n",
    "\n",
    "    education = [{\n",
    "        \"district\": district_id(e),\n",
    "        \"year\": str(year),\n",
    "        \"education\": (\n",
    "            e[\"B15003_019E\"] +\n",
    "            e[\"B15003_020E\"] +\n",
    "            e[\"B15003_021E\"] +\n",
    "            e[\"B15003_022E\"] +\n",
    "            e[\"B15003_023E\"] +\n",
    "            e[\"B15003_024E\"] +\n",
    "            e[\"B15003_025E\"]\n",
    "        ) / e[\"B15003_001E\"],\n",
    "    } for e in c.acs5.get([\n",
    "        'B15003_001E',\n",
    "        'B15003_019E',\n",
    "        'B15003_020E',\n",
    "        'B15003_021E',\n",
    "        'B15003_022E',\n",
    "        'B15003_023E',\n",
    "        'B15003_024E',\n",
    "        'B15003_025E'\n",
    "    ], {'for': 'congressional district:*'}, year=year)]\n",
    "    \n",
    "    normalize_values(\"education\", education)\n",
    "    \n",
    "    \n",
    "    # DENSITY\n",
    "\n",
    "    POP = {}\n",
    "    \n",
    "    for d in c.acs5.get(['B01003_001E'], {'for': 'congressional district:*'}, year=year):\n",
    "        district = district_id(d)\n",
    "        POP[district] = int(d[\"B01003_001E\"])\n",
    "    \n",
    "    response = requests.get('https://www2.census.gov/geo/relfiles/cdsld16/natl/natl_landarea_cd_delim.txt')\n",
    "    text = \"\\n\".join(response.text.split(\"\\n\")[1:])\n",
    "    \n",
    "    # Manually add at-large districts which aren't included in the geo data\n",
    "    # We get land area from here:\n",
    "    # https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml\n",
    "    text += \"02,00,570640.95\\n\" # Alaska\n",
    "    text += \"10,00,1948.54\\n\" # Delaware\n",
    "    text += \"30,00,145545.80\\n\" # Montana\n",
    "    text += \"38,00,69000.80\\n\" # North Dakota\n",
    "    text += \"46,00,75811.00\\n\" # South Dakota\n",
    "    text += \"50,00,9216.66\\n\" # Vermont\n",
    "    text += \"56,00,97093.14\\n\" # Wyoming\n",
    "    \n",
    "    reader = csv.DictReader(io.StringIO(text))\n",
    "    \n",
    "    def alt_id(d):\n",
    "        return \"{}-{}\".format(\n",
    "            us.states.lookup(d[\"State\"]).abbr,\n",
    "            d[\"Congressional District\"]\n",
    "        )\n",
    "    \n",
    "    density = [\n",
    "        {\n",
    "            \"district\": alt_id(d),\n",
    "            \"density\": POP[alt_id(d)] / float(d[\"Land Area\"])\n",
    "        } for d in reader\n",
    "    ]\n",
    "    \n",
    "    normalize_values(\"density\", density)\n",
    "    \n",
    "    return DISTRICTS\n",
    "\n",
    "\n",
    "CENSUS_DISTRICTS = get_district_census_series(2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def get_distance(districtDemos, comparitorDemos):\n",
    "    w = [\n",
    "        WEIGHTS[\"white\"],\n",
    "        WEIGHTS[\"black\"],\n",
    "        WEIGHTS[\"hispanic\"],\n",
    "        WEIGHTS[\"asian\"],\n",
    "        WEIGHTS[\"age\"],\n",
    "        WEIGHTS[\"income\"],\n",
    "        WEIGHTS[\"education\"],\n",
    "        WEIGHTS[\"density\"]\n",
    "    ]\n",
    "    district = [\n",
    "        districtDemos[\"white_norm\"],\n",
    "        districtDemos[\"black_norm\"],\n",
    "        districtDemos[\"hispanic_norm\"],\n",
    "        districtDemos[\"asian_norm\"],\n",
    "        districtDemos[\"age_norm\"],\n",
    "        districtDemos[\"income_norm\"],\n",
    "        districtDemos[\"education_norm\"],\n",
    "        districtDemos[\"density_norm\"],\n",
    "    ]\n",
    "    comparitor = [\n",
    "        comparitorDemos[\"white_norm\"],\n",
    "        comparitorDemos[\"black_norm\"],\n",
    "        comparitorDemos[\"hispanic_norm\"],\n",
    "        comparitorDemos[\"asian_norm\"],\n",
    "        comparitorDemos[\"age_norm\"],\n",
    "        comparitorDemos[\"income_norm\"],\n",
    "        comparitorDemos[\"education_norm\"],\n",
    "        comparitorDemos[\"density_norm\"],\n",
    "    ]\n",
    "    return distance.euclidean(district, comparitor, w)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "district_distances = {}\n",
    "\n",
    "exclude = ['DC-98', 'PR-98']\n",
    "\n",
    "districts = [d for d in CENSUS_DISTRICTS.keys() if d not in exclude]\n",
    "\n",
    "for district, districtDemos in CENSUS_DISTRICTS.items():\n",
    "    if district in exclude:\n",
    "        continue\n",
    "    district_distances[district] = []\n",
    "    for comparitor, comparitorDemos in CENSUS_DISTRICTS.items():\n",
    "        if district == comparitor or comparitor in exclude:\n",
    "            continue\n",
    "        district_distances[district].append({\n",
    "            'district': comparitor,\n",
    "            'distance': get_distance(districtDemos, comparitorDemos)\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each district we calculate the **22** most similar districts, about 5% of the total number of districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_district_ids = {}\n",
    "similar_districts = {}\n",
    "\n",
    "for district, distances in district_distances.items():\n",
    "    sorted_distances = list(sorted(distances, key=lambda k: k['distance']))\n",
    "    similar_district_ids[district] = [k['district'] for k in sorted_distances[:N]]\n",
    "    similar_districts[district] = sorted_distances[:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/demographic-similarity.json', 'w') as file:\n",
    "    json.dump(similar_district_ids, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV with similarity score stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/demographic-similarity.csv','w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['district', 'min_similarity', 'max_similarity', 'similarity_range', 'most_similar ⬅'])\n",
    "\n",
    "    for district in districts:\n",
    "        MIN = similar_districts[district][0]['distance']\n",
    "        MAX = similar_districts[district][-1]['distance']\n",
    "        row = [district, MIN, MAX, MAX - MIN] + [k['district'] for k in similar_districts[district]]\n",
    "        \n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare demographic profiles of top 5 similar districts\n",
    "\n",
    "See how close the demographic profiles of the most similar districts line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measures(district):\n",
    "    return [\n",
    "        CENSUS_DISTRICTS[district]['white_norm'],\n",
    "        CENSUS_DISTRICTS[district]['black_norm'],\n",
    "        CENSUS_DISTRICTS[district]['hispanic_norm'],\n",
    "        CENSUS_DISTRICTS[district]['asian_norm'],\n",
    "        CENSUS_DISTRICTS[district]['age_norm'],\n",
    "        CENSUS_DISTRICTS[district]['income_norm'],\n",
    "        CENSUS_DISTRICTS[district]['education_norm'],\n",
    "        CENSUS_DISTRICTS[district]['density_norm']\n",
    "    ]\n",
    "    \n",
    "\n",
    "with open('data/demographic-similarity-top-5.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\n",
    "        'district',\n",
    "        'white',\n",
    "        'black',\n",
    "        'hispanic',\n",
    "        'asian',\n",
    "        'age',\n",
    "        'income',\n",
    "        'education',\n",
    "        'density'\n",
    "    ])\n",
    "    \n",
    "    for district in districts:\n",
    "        district_measures = get_measures(district)\n",
    "        similars = []\n",
    "        writer.writerow([])\n",
    "        writer.writerow([district] + district_measures)\n",
    "        top5 = similar_districts[district][:5]\n",
    "        for d in top5:\n",
    "            similar_measures = get_measures(d['district'])\n",
    "            similars.append(similar_measures)\n",
    "            writer.writerow([d['district']] + similar_measures)\n",
    "        variances = ['VARIANCE',]\n",
    "        for m in district_measures:\n",
    "            i = district_measures.index(m)\n",
    "            variance = 0\n",
    "            for s in similars:\n",
    "                variance += (m - s[i])\n",
    "            variances.append(variance)\n",
    "        writer.writerow(variances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare similarity maps to POLITICO race ratings\n",
    "\n",
    "These maps list the ratings of similar districts. We also calculate the variance for each map based on a point scale for the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import pvariance\n",
    "\n",
    "response = requests.get('https://www.politico.com/election-results/2018/race-ratings/data/ratings.json')\n",
    "ratings = {}\n",
    "rating_codes = {}\n",
    "\n",
    "for rating in response.json():\n",
    "    ratings[rating['id']] = rating['latest_rating']['short_label']\n",
    "    rating_codes[ratings[rating['id']]] = rating['latest_rating']['order']\n",
    "\n",
    "    \n",
    "with open('data/demographic-similarity-with-ratings.csv','w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['district', 'rating', 'variance', 'most_similar_ratings'])\n",
    "    \n",
    "    for district in districts:\n",
    "        row = [\n",
    "            district,\n",
    "            ratings[district],\n",
    "            pvariance([rating_codes[ratings[k['district']]] for k in similar_districts[district]])\n",
    "        ] + [ratings[k['district']] for k in similar_districts[district]]\n",
    "        \n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "with open('data/demographic-similarity.json', 'rb') as data:\n",
    "    key = 'election-results/2018/district-similarity-maps/demographic-similarity.json'\n",
    "    s3.Bucket(os.getenv('AWS_S3_BUCKET')).put_object(\n",
    "        Key=key,\n",
    "        Body=data,\n",
    "        ACL='public-read',\n",
    "        CacheControl='max-age=300',\n",
    "        ContentType='application/json'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

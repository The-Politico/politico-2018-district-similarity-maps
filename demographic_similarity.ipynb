{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![POLITICO](https://rawgithub.com/The-Politico/src/master/images/logo/badge.png)\n",
    "\n",
    "# POLITICO demographic district similarity maps\n",
    "\n",
    "POLITICO demographic district similarity maps create lists of the most similar districts to any one district based on census demographics.\n",
    "\n",
    "The maps are created by calculating a weighted Euclidean distance between demographic characteristics in each district."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data\n",
    "\n",
    "Demographic profile for districts is based on four characteristics:\n",
    "\n",
    "- Non-hispanic whiteness (B03002)\n",
    "- Age (B01002)\n",
    "- Median Income (B19013)\n",
    "- Education attainment (B15003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Calculating weights\n",
    "\n",
    "We weight demographic variables by how significant they are in determing a political identity. To do that, we establish the statistical relationship between the variables and voting behavior in a multivariate linear model.\n",
    "\n",
    "While our goal is to determine the similarity of districts, we use county-level returns and demographic measures to calculate our weights because there are more counties than districts in which to test the relationship between demographics and voting. Our voting data (dependent) is 2012 and 2016 presidential results. Our demographic data (independent) comes from the 2012 and 2016 5-year American Community Survey. In the model, we weight 2016 double 2012 data.\n",
    "\n",
    "To calculate the weights, we need to estimate how influential each variable is compared to each other in terms of its impact on party margin.\n",
    "\n",
    "To begin we normalize our demographic variables to a scale of 0 to 1 representing the min and max of each variable's distribution. That way we can compare their model coefficients. We then take the absolute value of the coefficients and simplify them to a ratio. That ratio represents how influential they are compared to each other when used together to predict voting behavior. These are our weights.\n",
    "\n",
    "For example, if non-hispanic whiteness has a coefficient of 4 while age has a coefficent of 2 in the model, we weight whiteness 2 to 1 when calculating our Euclidean distanct between districts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Get census data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from census import Census\n",
    "from us import states\n",
    "\n",
    "c = Census(os.getenv('CENSUS_API_KEY'))\n",
    "\n",
    "\n",
    "def get_census_series(year):\n",
    "    FIPS = {}\n",
    "    FIPS_POP = {}\n",
    "    \n",
    "    def add_to_fips(d):\n",
    "        if d[\"fips\"] not in FIPS:\n",
    "            FIPS[d[\"fips\"]] = {}\n",
    "        FIPS[d[\"fips\"]] = {**FIPS[d[\"fips\"]], **d}\n",
    "    \n",
    "    # Get total population in a dict\n",
    "    for d in c.acs5.get(['B03002_001E'], {'for': 'county:*'}, year=year):\n",
    "        fips = d[\"state\"] + d[\"county\"]\n",
    "        FIPS_POP[fips] = int(d[\"B03002_001E\"])\n",
    "    \n",
    "    white = [{\n",
    "        \"fips\": w[\"state\"] + w[\"county\"],\n",
    "        \"year\": str(year),\n",
    "        \"white\": w[\"B03002_003E\"] / w[\"B03002_001E\"]\n",
    "    } for w in c.acs5.get(['B03002_003E', 'B03002_001E'], {'for': 'county:*'}, year=year)]\n",
    "    white_values = [d[\"white\"] for d in white]\n",
    "    white_max = max(white_values)\n",
    "    white_min = min(white_values)\n",
    "    for d in white:\n",
    "        d[\"white_norm\"] = (d[\"white\"] - white_min) / (white_max - white_min)\n",
    "        add_to_fips(d)\n",
    "    white.sort(key=lambda d: d[\"fips\"])\n",
    "\n",
    "    age = [{\n",
    "        \"fips\": a[\"state\"] + a[\"county\"],\n",
    "        \"year\": str(year),\n",
    "        \"age\": a[\"B01002_001E\"]\n",
    "    } for a in c.acs5.get('B01002_001E', {'for': 'county:*'}, year=year)]\n",
    "    age_values = [d[\"age\"] for d in age]\n",
    "    age_max = max(age_values)\n",
    "    age_min = min(age_values)\n",
    "    for d in age:\n",
    "        d[\"age_norm\"] = (d[\"age\"] - age_min) / (age_max - age_min)\n",
    "        add_to_fips(d)\n",
    "    age.sort(key=lambda d: d[\"fips\"])\n",
    "\n",
    "    income = [{\n",
    "        \"fips\": i[\"state\"] + i[\"county\"],\n",
    "        \"year\": str(year),\n",
    "        \"income\": i[\"B19013_001E\"]\n",
    "    } for i in c.acs5.get('B19013_001E', {'for': 'county:*'}, year=year)]\n",
    "    income_values = [d[\"income\"] for d in income]\n",
    "    income_max = max(income_values)\n",
    "    income_min = min(income_values)\n",
    "    for d in income:\n",
    "        d[\"income_norm\"] = (d[\"income\"] - income_min) / (income_max - income_min)\n",
    "        add_to_fips(d)\n",
    "    income.sort(key=lambda d: d[\"fips\"])\n",
    "\n",
    "    education = [{\n",
    "        \"fips\": e[\"state\"] + e[\"county\"],\n",
    "        \"year\": str(year),\n",
    "        \"education\": (\n",
    "            e[\"B15003_019E\"] +\n",
    "            e[\"B15003_020E\"] +\n",
    "            e[\"B15003_021E\"] +\n",
    "            e[\"B15003_022E\"] +\n",
    "            e[\"B15003_023E\"] +\n",
    "            e[\"B15003_024E\"] +\n",
    "            e[\"B15003_025E\"]\n",
    "        ) / e[\"B15003_001E\"],\n",
    "    } for e in c.acs5.get([\n",
    "        'B15003_001E',\n",
    "        'B15003_019E',\n",
    "        'B15003_020E',\n",
    "        'B15003_021E',\n",
    "        'B15003_022E',\n",
    "        'B15003_023E',\n",
    "        'B15003_024E',\n",
    "        'B15003_025E'\n",
    "    ], {'for': 'county:*'}, year=year)]\n",
    "    education_values = [d[\"education\"] for d in education]\n",
    "    education_max = max(education_values)\n",
    "    education_min = min(education_values)\n",
    "    for d in education:\n",
    "        d[\"education_norm\"] = (d[\"education\"] - education_min) / (education_max - education_min)\n",
    "        add_to_fips(d)\n",
    "    education.sort(key=lambda d: d[\"fips\"])\n",
    "    \n",
    "    density = [\n",
    "        {\n",
    "            \"fips\": d[\"state\"] + d[\"county\"],\n",
    "            \"density\": FIPS_POP[d[\"state\"] + d[\"county\"]] / int(d[\"AREALAND\"])\n",
    "        } for d in c.sf1.get('AREALAND', {'for': 'county:*'}, year=2010) if d[\"state\"] + d[\"county\"] in FIPS_POP\n",
    "    ]\n",
    "    density_values = [d[\"density\"] for d in density]\n",
    "    density_max = max(density_values)\n",
    "    density_min = min(density_values)\n",
    "    for d in density:\n",
    "        d[\"density_norm\"] = (d[\"density\"] - density_min) / (density_max - density_min)\n",
    "        add_to_fips(d)\n",
    "    \n",
    "    \n",
    "    return FIPS\n",
    "\n",
    "CENSUS_2016 = get_census_series(2016)\n",
    "CENSUS_2012 = get_census_series(2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Get election data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_results_year(year):\n",
    "    response = requests.get('https://raw.githubusercontent.com/The-Politico/presidential-county-data/master/output/{}.csv'.format(year))\n",
    "\n",
    "    results = {}\n",
    "    txt\n",
    "    reader = csv.DictReader(io.StringIO(response.text))\n",
    "    for row in reader:\n",
    "        fips = row['county_fips']\n",
    "        results[fips] = {\n",
    "            \"dem\": int(row['democrat']),\n",
    "            \"dem_pct\": int(row[\"democrat\"]) / int(row[\"total\"]),\n",
    "            \"gop\": int(row['republican']),\n",
    "            \"gop_pct\": int(row[\"republican\"]) / int(row[\"total\"]),\n",
    "            \"total\": int(row['total']),\n",
    "            \"margin\": (int(row[\"democrat\"]) / int(row[\"total\"])) - (int(row[\"republican\"]) / int(row[\"total\"]))\n",
    "        }\n",
    "    return results\n",
    "\n",
    "RESULTS_2012 = get_results_year(2012)\n",
    "RESULTS_2016 = get_results_year(2016)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.38875571065021575\n",
      "\n",
      "Coefficients {'white': -0.8512145403228027, 'age': 0.12831134722076493, 'income': -0.15450339436212904, 'education': 0.7075274067274355, 'density': 1.5896494061548279}\n",
      "\n",
      "Weights {'white': 0.8512145403228027, 'age': 0.12831134722076493, 'income': 0.15450339436212904, 'education': 0.7075274067274355, 'density': 1.5896494061548279}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "w = []\n",
    "\n",
    "for fips, demos in CENSUS_2016.items():\n",
    "    if fips not in RESULTS_2016:\n",
    "        continue\n",
    "    y.append(RESULTS_2016[fips][\"margin\"])\n",
    "    X.append([\n",
    "        demos[\"white_norm\"],\n",
    "        demos[\"age_norm\"],\n",
    "        demos[\"income_norm\"],\n",
    "        demos[\"education_norm\"],\n",
    "        demos[\"density_norm\"],\n",
    "    ])\n",
    "    w.append(2)\n",
    "\n",
    "for fips, demos in CENSUS_2012.items():\n",
    "    if fips not in RESULTS_2012:\n",
    "        continue\n",
    "    y.append(RESULTS_2012[fips][\"margin\"])\n",
    "    X.append([\n",
    "        demos[\"white_norm\"],\n",
    "        demos[\"age_norm\"],\n",
    "        demos[\"income_norm\"],\n",
    "        demos[\"education_norm\"],\n",
    "        demos[\"density_norm\"],\n",
    "    ])\n",
    "    w.append(1)\n",
    "\n",
    "model = LinearRegression().fit(X, y, w)\n",
    "\n",
    "print('R2:', model.score(X, y, w))\n",
    "coefficients = {\n",
    "    'white': model.coef_[0],\n",
    "    'age': model.coef_[1],\n",
    "    'income': model.coef_[2],\n",
    "    'education': model.coef_[3],\n",
    "    'density': model.coef_[4]\n",
    "}\n",
    "print('\\nCoefficients', coefficients)\n",
    "\n",
    "WEIGHTS = {\n",
    "    'white': abs(model.coef_[0]),\n",
    "    'age': abs(model.coef_[1]),\n",
    "    'income': abs(model.coef_[2]),\n",
    "    'education': abs(model.coef_[3]),\n",
    "    'density': abs(model.coef_[4])\n",
    "}\n",
    "print('\\nWeights', WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www2.census.gov/geo/relfiles/cdsld16/natl/natl_landarea_cd_delim.txt'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'https://www2.census.gov/geo/relfiles/cdsld16/natl/natl_landarea_cd_delim.txt'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
